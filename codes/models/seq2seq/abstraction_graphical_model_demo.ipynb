{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from decode_graphical_models import *\n",
    "from decode_abstract_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../../data-files/gSCAN-Simple/data-compositional-splits.txt\"\n",
    "data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM = 200\n",
    "agent_positions_batch = []\n",
    "target_positions_batch = []\n",
    "target_commands = []\n",
    "for ex in data_json[\"examples\"][\"train\"]:\n",
    "    target_commands += [ex[\"target_commands\"]]\n",
    "    situation_repr = ex['situation']\n",
    "    agent = torch.tensor(\n",
    "        (int(situation_repr[\"agent_position\"][\"row\"]) * int(situation_repr[\"grid_size\"])) +\n",
    "        int(situation_repr[\"agent_position\"][\"column\"]), dtype=torch.long).unsqueeze(dim=0)\n",
    "    target = torch.tensor(\n",
    "        (int(situation_repr[\"target_object\"][\"position\"][\"row\"]) * int(situation_repr[\"grid_size\"])) +\n",
    "        int(situation_repr[\"target_object\"][\"position\"][\"column\"]), dtype=torch.long).unsqueeze(dim=0)\n",
    "    agent_positions_batch.append(agent)\n",
    "    target_positions_batch.append(target)\n",
    "    if len(agent_positions_batch) == NUM:\n",
    "        break\n",
    "agent_positions_batch = torch.stack(agent_positions_batch, dim=0)\n",
    "target_positions_batch = torch.stack(target_positions_batch, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_model = HighLevelModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = hi_model(agent_positions_batch, target_positions_batch, tag=\"situation_encode\")\n",
    "actions = torch.zeros(hidden_states.size(0), 1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sequence = []\n",
    "actions_length = torch.zeros(hidden_states.size(0), 1).long()\n",
    "for i in range(20):\n",
    "    hidden_states, actions = hi_model(\n",
    "        hmm_states=hidden_states, \n",
    "        hmm_actions=actions, \n",
    "        tag=\"_hmm_step_fxn\"\n",
    "    )\n",
    "    actions_length += (actions!=0).long()\n",
    "    actions_sequence += [actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sequence = torch.cat(actions_sequence, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(actions_sequence.size(0)):\n",
    "    pred = (hi_model.actions_list_to_sequence(actions_sequence[i,:actions_length[i]].tolist()))\n",
    "    actual = target_commands[i]\n",
    "    assert pred == actual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
