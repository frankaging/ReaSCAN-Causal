{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script works on transform the seq2seq model to a graphical model using antra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "import json\n",
    "from model import *\n",
    "from ReaSCAN_dataset import *\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from antra.antra import *\n",
    "from decode_graphical_models import *\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "def isnotebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "if isnotebook():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "# setting up the seeds.\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize ReaSCAN dataset to load config of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 01:25 Formulating the dataset from the passed in json file...\n",
      "2021-08-14 01:25 Loading vocabularies...\n",
      "2021-08-14 01:25 Done loading vocabularies.\n",
      "2021-08-14 01:25 Converting dataset to tensors...\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"../../../data-files/gSCAN-Simple/\"\n",
    "data_file = \"data-compositional-splits.txt\"\n",
    "input_vocab_file = \"input_vocabulary.txt\"\n",
    "target_vocab_file = \"target_vocabulary.txt\"\n",
    "dataset = ReaSCANDataset(\n",
    "    json.load(open(os.path.join(data_directory, data_file), \"r\")), \n",
    "    data_directory, split=\"train\",\n",
    "    input_vocabulary_file=input_vocab_file,\n",
    "    target_vocabulary_file=target_vocab_file,\n",
    "    generate_vocabulary=False,\n",
    "    k=0,\n",
    ")\n",
    "# Loading a couple of example from ReaSCAN.\n",
    "dataset.read_dataset(\n",
    "    max_examples=100,\n",
    "    simple_situation_representation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.save_vocabularies(\n",
    "#     input_vocabulary_file=\"input_vocabulary.txt\", \n",
    "#     target_vocabulary_file=\"target_vocabulary.txt\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading model to the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    input_vocabulary_size=dataset.input_vocabulary_size,\n",
    "    target_vocabulary_size=dataset.target_vocabulary_size,\n",
    "    num_cnn_channels=dataset.image_channels,\n",
    "    input_padding_idx=dataset.input_vocabulary.pad_idx,\n",
    "    target_pad_idx=dataset.target_vocabulary.pad_idx,\n",
    "    target_eos_idx=dataset.target_vocabulary.eos_idx,\n",
    "    # language encoder config\n",
    "    embedding_dimension=25,\n",
    "    encoder_hidden_size=100,\n",
    "    num_encoder_layers=1,\n",
    "    encoder_dropout_p=0.3,\n",
    "    encoder_bidirectional=True,\n",
    "    # world encoder config\n",
    "    simple_situation_representation=True,\n",
    "    cnn_hidden_num_channels=50,\n",
    "    cnn_kernel_size=7,\n",
    "    cnn_dropout_p=0.1,\n",
    "    auxiliary_task=False,\n",
    "    # decoder config\n",
    "    num_decoder_layers=1,\n",
    "    attention_type=\"bahdanau\",\n",
    "    decoder_dropout_p=0.3,\n",
    "    decoder_hidden_size=100,\n",
    "    conditional_attention=True,\n",
    "    output_directory=\"../../../saved_models/gSCAN-Simple/\"\n",
    ")\n",
    "model.eval()\n",
    "model.to(device)\n",
    "G = ReaSCANMultiModalLSTMCompGraph(\n",
    "    model=model,\n",
    "    max_decode_step=13,\n",
    "    is_cf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, _ = dataset.get_dual_dataset()\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading some examples to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "    # just using this loop to get a pair of examples\n",
    "    input_batch, target_batch, situation_batch, \\\n",
    "        agent_positions_batch, target_positions_batch, \\\n",
    "        input_lengths_batch, target_lengths_batch, \\\n",
    "        dual_input_batch, dual_target_batch, dual_situation_batch, \\\n",
    "        dual_agent_positions_batch, dual_target_positions_batch, \\\n",
    "        dual_input_lengths_batch, dual_target_lengths_batch = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "low1 = {\n",
    "    \"commands_input\": input_batch, \n",
    "    \"commands_lengths\": input_lengths_batch,\n",
    "    \"situations_input\": situation_batch,\n",
    "    \"target_batch\": target_batch,\n",
    "    \"target_lengths\": target_lengths_batch,\n",
    "}\n",
    "low1 = GraphInput(low1, batched=True, batch_dim=0, cache_results=False)\n",
    "\n",
    "low2 = {\n",
    "    \"commands_input\": dual_input_batch, \n",
    "    \"commands_lengths\": dual_input_lengths_batch,\n",
    "    \"situations_input\": dual_situation_batch,\n",
    "    \"target_batch\": dual_target_batch,\n",
    "    \"target_lengths\": dual_target_lengths_batch,\n",
    "}\n",
    "low2 = GraphInput(low2, batched=True, batch_dim=0, cache_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "low2_hidden = G.compute_node('lstm_step_2', low2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4638])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low2_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lstm_step_2[::,0:2:]': tensor([[0.7991, 0.7719],\n",
      "        [0.5270, 0.2030]])}\n"
     ]
    }
   ],
   "source": [
    "intervention_dict = {\"lstm_step_2[:,0:2]\": torch.rand(2,2)}\n",
    "low_interv = Intervention(\n",
    "    low1, intervention_dict, \n",
    "    cache_results=False,\n",
    "    cache_base_results=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1271,  0.1078,  0.0014,  ...,  0.0408,  0.0281,  0.0707]],\n",
       "        grad_fn=<CatBackward>),\n",
       " tensor([[-0.1271,  0.1078,  0.0014,  ...,  0.0408,  0.0281,  0.0707]],\n",
       "        grad_fn=<CatBackward>))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.intervene_node(\"lstm_step_0\", low_interv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up training loop for this model in antra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': [(('commands_input', (1, 3, 4, 5, 6, 7, 8, 2)),\n",
       "           ('commands_lengths', (8,)),\n",
       "           ('situations_input',\n",
       "            (((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
       "               1.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)))),\n",
       "           ('target_batch', (1, 4, 4, 4, 4, 3, 4, 4, 2, 0, 0, 0, 0)),\n",
       "           ('target_lengths', (9,))),\n",
       "          (('commands_input', (1, 3, 4, 5, 6, 7, 8, 2)),\n",
       "           ('commands_lengths', (8,)),\n",
       "           ('situations_input',\n",
       "            (((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
       "               1.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)),\n",
       "             ((0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0),\n",
       "              (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0)))),\n",
       "           ('target_batch', (1, 4, 4, 3, 4, 4, 2, 0, 0, 0, 0, 0, 0)),\n",
       "           ('target_lengths', (7,)))],\n",
       " 'interv': (('lstm_step_2[::,0:2:]',\n",
       "             ((0.7014985680580139, 0.12989318370819092),\n",
       "              (0.9880610108375549, 0.5216811299324036))),),\n",
       " 'locs': {'lstm_step_2': (slice(None, None, None), slice(0, 2, None))}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_interv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
