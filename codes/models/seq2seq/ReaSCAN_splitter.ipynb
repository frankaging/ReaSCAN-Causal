{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read-in ReaSCAN and Manipulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "from ReaSCAN_dataset import *\n",
    "\n",
    "# Init of the vocab.\n",
    "intransitive_verbs = [\"walk\"]\n",
    "transitive_verbs = [\"push\", \"pull\"]\n",
    "adverbs = [\"while zigzagging\", \"while spinning\", \"cautiously\", \"hesitantly\"]\n",
    "nouns = [\"circle\", \"cylinder\", \"square\", \"box\"]\n",
    "color_adjectives = [\"red\", \"blue\", \"green\", \"yellow\"]\n",
    "size_adjectives = [\"big\", \"small\"]\n",
    "relative_pronouns = [\"that is\"]\n",
    "relation_clauses = [\"in the same row as\", \n",
    "                    \"in the same column as\", \n",
    "                    \"in the same color as\", \n",
    "                    \"in the same shape as\", \n",
    "                    \"in the same size as\",\n",
    "                    \"inside of\"]\n",
    "vocabulary = ReaSCANVocabulary.initialize(intransitive_verbs=intransitive_verbs,\n",
    "                                   transitive_verbs=transitive_verbs, adverbs=adverbs, nouns=nouns,\n",
    "                                   color_adjectives=color_adjectives,\n",
    "                                   size_adjectives=size_adjectives, \n",
    "                                   relative_pronouns=relative_pronouns, \n",
    "                                   relation_clauses=relation_clauses)\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "object_vocabulary = ObjectVocabulary(shapes=vocabulary.get_semantic_shapes(),\n",
    "                                     colors=vocabulary.get_semantic_colors(),\n",
    "                                     min_size=min_object_size, max_size=max_object_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in info.\n",
    "path_to_data = \"../../../data-files/ReaSCAN-Simple/data-compositional-splits.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command: walk,to,the,big,yellow,cylinder,cautiously\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: ['walk', 'walk', 'turn right', 'walk', 'walk']\n"
     ]
    }
   ],
   "source": [
    "example = ReaSCAN_data_json[\"examples\"][\"train\"][random.randint(0, len(ReaSCAN_data_json[\"examples\"][\"train\"])-1)]\n",
    "command = example[\"command\"]\n",
    "print(f\"command: {command}\")\n",
    "situation = example[\"situation\"]\n",
    "world = World(grid_size=6, colors=vocabulary.get_semantic_colors(),\n",
    "              object_vocabulary=object_vocabulary,\n",
    "              shapes=vocabulary.get_semantic_shapes(),\n",
    "              save_directory=\"./tmp/\")\n",
    "world.clear_situation()\n",
    "for obj_idx, obj in situation[\"placed_objects\"].items():\n",
    "    world.place_object(\n",
    "        Object(size=int(obj[\"object\"][\"size\"]), color=obj[\"object\"][\"color\"], shape=obj[\"object\"][\"shape\"]), \n",
    "        position=Position(row=int(obj[\"position\"][\"row\"]), column=int(obj[\"position\"][\"column\"]))\n",
    "    )\n",
    "world.place_agent_at(\n",
    "    Position(\n",
    "        row=int(situation[\"agent_position\"][\"row\"]), \n",
    "        column=int(situation[\"agent_position\"][\"column\"])\n",
    "))\n",
    "_ = world.render_simple()\n",
    "\n",
    "# HERE: you can change to other target object.\n",
    "target_position = Position(\n",
    "    row=int(situation['target_object']['position'][\"row\"]), \n",
    "    column=int(situation['target_object']['position'][\"column\"])\n",
    ")\n",
    "world.go_to_position(position=target_position, manner='', primitive_command=\"walk\")\n",
    "target_commands, target_demonstration = world.get_current_observations()\n",
    "print(f\"action: {target_commands}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for the new length split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../../codes/Reason-SCAN/data-files/ReaSCAN-Causal-new-action-sequence/data-train.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = ReaSCAN_data_json[\"examples\"][\"train\"]\n",
    "max_target_commands_len = -1\n",
    "for example in all_data:\n",
    "    seq_len = len(example['target_commands'].split(\",\"))\n",
    "    if seq_len > max_target_commands_len:\n",
    "        max_target_commands_len = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(max_target_commands_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dist_data = []\n",
    "out_dist_data = []\n",
    "for example in all_data:\n",
    "    seq_len = len(example['target_commands'].split(\",\"))\n",
    "    if seq_len >= 12: # 12 or 13\n",
    "        out_dist_data += [example]\n",
    "    else:\n",
    "        in_dist_data += [example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 85000 # we want to lower this number a bit from the fullset to make training time reasonable.\n",
    "eval_len = int(len(in_dist_data)*0.05) # let us take 5% for dev and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(in_dist_data)\n",
    "train_set = in_dist_data[:train_len]\n",
    "dev_set = in_dist_data[-2*eval_len:-eval_len]\n",
    "test_set = in_dist_data[-eval_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReaSCAN_data_json[\"examples\"] = {\n",
    "    \"train\":train_set,\n",
    "    \"test\":test_set,\n",
    "    \"dev\":dev_set,\n",
    "    \"new_action_length\":out_dist_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to the disk.\n",
    "with open(\"../../../data-files/ReaSCAN-novel-action-length/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(ReaSCAN_data_json, fd, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for the new direction split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../../codes/Reason-SCAN/data-files/ReaSCAN-Causal-new-action-sequence/data-train.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = ReaSCAN_data_json[\"examples\"][\"train\"]\n",
    "in_dist_data = []\n",
    "out_dist_data = []\n",
    "for example in all_data:\n",
    "    if \"walk\" not in example[\"command\"]:\n",
    "        assert False\n",
    "    if example[\"adverb_in_command\"] != \"\":\n",
    "        assert False\n",
    "    agent_r = int(example['situation']['agent_position'][\"row\"])\n",
    "    agent_c = int(example['situation']['agent_position'][\"column\"])\n",
    "    target_r = int(example['situation']['target_object']['position'][\"row\"])\n",
    "    target_c = int(example['situation']['target_object']['position'][\"column\"])\n",
    "    r_diff = target_r-agent_r\n",
    "    c_diff = target_c-agent_c\n",
    "    if r_diff > 0 and c_diff < 0:\n",
    "        out_dist_data += [example]\n",
    "    else:\n",
    "        in_dist_data += [example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 85000 # we want to lower this number a bit from the fullset to make training time reasonable.\n",
    "eval_len = int(len(in_dist_data)*0.05) # let us take 5% for dev and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(in_dist_data)\n",
    "train_set = in_dist_data[:train_len]\n",
    "dev_set = in_dist_data[-2*eval_len:-eval_len]\n",
    "test_set = in_dist_data[-eval_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(out_dist_data)\n",
    "ReaSCAN_data_json[\"examples\"] = {\n",
    "    \"train\":train_set,\n",
    "    \"test\":test_set,\n",
    "    \"dev\":dev_set,\n",
    "    \"new_direction\":out_dist_data[:8000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to the disk.\n",
    "with open(\"../../../data-files/ReaSCAN-novel-direction/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(ReaSCAN_data_json, fd, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for the new attribute split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../../codes/Reason-SCAN/data-files/ReaSCAN-Causal-new-attribute/data-train.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = ReaSCAN_data_json[\"examples\"][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_color = []\n",
    "new_size = []\n",
    "in_dist_data = []\n",
    "for example in all_data:\n",
    "    if \"yellow,square\" in example['command']:\n",
    "        new_color += [example]\n",
    "    elif \"small,cylinder\" in example['command'] or \\\n",
    "        \"small,red,cylinder\" in example['command'] or \\\n",
    "        \"small,blue,cylinder\" in example['command'] or \\\n",
    "        \"small,yellow,cylinder\" in example['command'] or \\\n",
    "        \"small,green,cylinder\" in example['command']:\n",
    "        new_size += [example]\n",
    "    else:\n",
    "        in_dist_data += [example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 85000 # we want to lower this number a bit from the fullset to make training time reasonable.\n",
    "eval_len = int(len(in_dist_data)*0.05) # let us take 5% for dev and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(in_dist_data)\n",
    "train_set = in_dist_data[:train_len]\n",
    "dev_set = in_dist_data[-2*eval_len:-eval_len]\n",
    "test_set = in_dist_data[-eval_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(new_color)\n",
    "random.shuffle(new_size)\n",
    "ReaSCAN_data_json[\"examples\"] = {\n",
    "    \"train\":train_set,\n",
    "    \"test\":test_set,\n",
    "    \"dev\":dev_set,\n",
    "    \"new_color\":new_color[:8000],\n",
    "    \"new_size\":new_size[:8000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to the disk.\n",
    "with open(\"../../../data-files/ReaSCAN-novel-attribute/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(ReaSCAN_data_json, fd, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us filter out very long sequence length\n",
    "# they are not the focus on this project and\n",
    "# burden training time a lot : )\n",
    "path_to_data = \"../../../data-files/ReaSCAN-novel-attribute/data-compositional-splits.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_color = []\n",
    "new_size = []\n",
    "train_data = []\n",
    "dev_data = []\n",
    "test_data = []\n",
    "for k, v in ReaSCAN_data_json[\"examples\"].items():\n",
    "    for example in v:\n",
    "        action_len = len(example[\"target_commands\"].split(\",\"))\n",
    "        if action_len > 35:\n",
    "            continue\n",
    "        if k == \"train\":\n",
    "            train_data += [example]\n",
    "        elif k == \"dev\":\n",
    "            dev_data += [example]\n",
    "        elif k == \"test\":\n",
    "            test_data += [example]\n",
    "        elif k == \"new_color\":\n",
    "            new_color += [example]\n",
    "        elif k == \"new_size\":\n",
    "            new_size += [example]\n",
    "        else:\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReaSCAN_data_json[\"examples\"] = {\n",
    "    \"train\":train_data,\n",
    "    \"test\":test_data,\n",
    "    \"dev\":dev_data,\n",
    "    \"new_color\":new_color[:8000],\n",
    "    \"new_size\":new_size[:8000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to the disk.\n",
    "with open(\"../../../data-files/ReaSCAN-novel-attribute/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(ReaSCAN_data_json, fd, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate vocab files for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../../data-files/\"\n",
    "datasets = [\n",
    "    \"ReaSCAN-novel-direction\",\n",
    "    \"ReaSCAN-novel-attribute\",\n",
    "    \"ReaSCAN-novel-action-length\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 13:14 Formulating the dataset from the passed in json file...\n",
      "2021-09-10 13:14 Generating vocabularies...\n",
      "2021-09-10 13:14 Populating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procecssing dataset=ReaSCAN-novel-direction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 13:17 Done generating vocabularies.\n",
      "2021-09-10 13:17 Formulating the dataset from the passed in json file...\n",
      "2021-09-10 13:17 Generating vocabularies...\n",
      "2021-09-10 13:17 Populating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procecssing dataset=ReaSCAN-novel-attribute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 13:19 Done generating vocabularies.\n",
      "2021-09-10 13:20 Formulating the dataset from the passed in json file...\n",
      "2021-09-10 13:20 Generating vocabularies...\n",
      "2021-09-10 13:20 Populating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procecssing dataset=ReaSCAN-novel-action-length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 13:22 Done generating vocabularies.\n"
     ]
    }
   ],
   "source": [
    "basic_stats = {}\n",
    "for ds in datasets:\n",
    "    path_to_data = os.path.join(dataset_path, ds, \"data-compositional-splits.txt\")\n",
    "    ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))\n",
    "    print(f\"procecssing dataset={ds}\")\n",
    "    train_dataset = ReaSCANDataset(\n",
    "        data_json=ReaSCAN_data_json, \n",
    "        save_directory=os.path.join(dataset_path, ds), \n",
    "        k=0, \n",
    "        split=\"train\", \n",
    "        generate_vocabulary=True\n",
    "    )\n",
    "    train_dataset.save_vocabularies(\n",
    "        input_vocabulary_file=\"input_vocabulary.txt\", \n",
    "        target_vocabulary_file=\"target_vocabulary.txt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will simply verify all testing vocab are seen during training.\n",
    "# for novel attributes, we want to make sure different composits are\n",
    "# seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify all examples contain three turn left as it is in SW.\n",
    "ds = \"ReaSCAN-novel-direction\"\n",
    "path_to_data = os.path.join(dataset_path, ds, \"data-compositional-splits.txt\")\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))\n",
    "\n",
    "for example in ReaSCAN_data_json[\"examples\"][\"new_direction\"]:\n",
    "    actions = example[\"target_commands\"].split(\",\")\n",
    "    action_counts = {}\n",
    "    for a in actions:\n",
    "        if a in action_counts:\n",
    "            action_counts[a] += 1\n",
    "        else:\n",
    "            action_counts[a] = 1\n",
    "    assert action_counts[\"turn left\"] == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify vocab are consistent.\n",
    "dataset_path = \"../../../data-files/\"\n",
    "datasets = [\n",
    "    \"ReaSCAN-novel-direction\",\n",
    "    \"ReaSCAN-novel-attribute\",\n",
    "    \"ReaSCAN-novel-action-length\"\n",
    "]\n",
    "\n",
    "for ds in datasets:\n",
    "    print(f\"verifying dataset={ds}\")\n",
    "    path_to_input_vocab = os.path.join(dataset_path, ds, \"input_vocabulary.txt\")\n",
    "    path_to_target_vocab = os.path.join(dataset_path, ds, \"target_vocabulary.txt\")\n",
    "    input_vocab = json.load(open(path_to_input_vocab, \"r\"))\n",
    "    target_vocab = json.load(open(path_to_target_vocab, \"r\"))\n",
    "    path_to_data = os.path.join(dataset_path, ds, \"data-compositional-splits.txt\")\n",
    "    ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))\n",
    "    for k, v in ReaSCAN_data_json[\"examples\"].items():\n",
    "        for example in v:\n",
    "            for w in example[\"command\"].split(\",\"):\n",
    "                assert w in input_vocab[\"idx_to_word\"]\n",
    "            for w in example[\"target_commands\"].split(\",\"):\n",
    "                assert w in target_vocab[\"idx_to_word\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
