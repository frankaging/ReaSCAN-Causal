{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read-in ReaSCAN and Manipulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "from ReaSCAN_dataset import *\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Init of the vocab.\n",
    "intransitive_verbs = [\"walk\"]\n",
    "transitive_verbs = [\"push\", \"pull\"]\n",
    "adverbs = [\"while zigzagging\", \"while spinning\", \"cautiously\", \"hesitantly\"]\n",
    "nouns = [\"circle\", \"cylinder\", \"square\", \"box\"]\n",
    "color_adjectives = [\"red\", \"blue\", \"green\", \"yellow\"]\n",
    "size_adjectives = [\"big\", \"small\"]\n",
    "relative_pronouns = [\"that is\"]\n",
    "relation_clauses = [\"in the same row as\", \n",
    "                    \"in the same column as\", \n",
    "                    \"in the same color as\", \n",
    "                    \"in the same shape as\", \n",
    "                    \"in the same size as\",\n",
    "                    \"inside of\"]\n",
    "vocabulary = ReaSCANVocabulary.initialize(intransitive_verbs=intransitive_verbs,\n",
    "                                   transitive_verbs=transitive_verbs, adverbs=adverbs, nouns=nouns,\n",
    "                                   color_adjectives=color_adjectives,\n",
    "                                   size_adjectives=size_adjectives, \n",
    "                                   relative_pronouns=relative_pronouns, \n",
    "                                   relation_clauses=relation_clauses)\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "object_vocabulary = ObjectVocabulary(shapes=vocabulary.get_semantic_shapes(),\n",
    "                                     colors=vocabulary.get_semantic_colors(),\n",
    "                                     min_size=min_object_size, max_size=max_object_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in info.\n",
    "path_to_data = \"../../../data-files/ReaSCAN-novel-attribute/data-compositional-splits.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command: walk,to,the,big,red,cylinder,hesitantly\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: ['turn left', 'turn left', 'walk', 'walk', 'turn right', 'walk', 'walk']\n"
     ]
    }
   ],
   "source": [
    "example = ReaSCAN_data_json[\"examples\"][\"train\"][random.randint(0, len(ReaSCAN_data_json[\"examples\"][\"train\"])-1)]\n",
    "command = example[\"command\"]\n",
    "print(f\"command: {command}\")\n",
    "situation = example[\"situation\"]\n",
    "world = World(grid_size=6, colors=vocabulary.get_semantic_colors(),\n",
    "              object_vocabulary=object_vocabulary,\n",
    "              shapes=vocabulary.get_semantic_shapes(),\n",
    "              save_directory=\"./tmp/\")\n",
    "world.clear_situation()\n",
    "for obj_idx, obj in situation[\"placed_objects\"].items():\n",
    "    world.place_object(\n",
    "        Object(size=int(obj[\"object\"][\"size\"]), color=obj[\"object\"][\"color\"], shape=obj[\"object\"][\"shape\"]), \n",
    "        position=Position(row=int(obj[\"position\"][\"row\"]), column=int(obj[\"position\"][\"column\"]))\n",
    "    )\n",
    "world.place_agent_at(\n",
    "    Position(\n",
    "        row=int(situation[\"agent_position\"][\"row\"]), \n",
    "        column=int(situation[\"agent_position\"][\"column\"])\n",
    "))\n",
    "_ = world.render_simple()\n",
    "\n",
    "# HERE: you can change to other target object.\n",
    "target_position = Position(\n",
    "    row=int(situation['target_object']['position'][\"row\"]), \n",
    "    column=int(situation['target_object']['position'][\"column\"])\n",
    ")\n",
    "world.go_to_position(position=target_position, manner='', primitive_command=\"walk\")\n",
    "target_commands, target_demonstration = world.get_current_observations()\n",
    "print(f\"action: {target_commands}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts for saving into disk for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command: push,the,cylinder\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn left,turn left,walk,push,push\n"
     ]
    }
   ],
   "source": [
    "# save the grid world into disk!\n",
    "example = ReaSCAN_data_json[\"examples\"][\"train\"][random.randint(0, len(ReaSCAN_data_json[\"examples\"][\"train\"])-1)]\n",
    "command = example[\"command\"]\n",
    "print(f\"command: {command}\")\n",
    "situation = example[\"situation\"]\n",
    "world = World(grid_size=6, colors=vocabulary.get_semantic_colors(),\n",
    "              object_vocabulary=object_vocabulary,\n",
    "              shapes=vocabulary.get_semantic_shapes(),\n",
    "              save_directory=\"./tmp/\")\n",
    "world.clear_situation()\n",
    "for obj_idx, obj in situation[\"placed_objects\"].items():\n",
    "    world.place_object(\n",
    "        Object(size=int(obj[\"object\"][\"size\"]), color=obj[\"object\"][\"color\"], shape=obj[\"object\"][\"shape\"]), \n",
    "        position=Position(row=int(obj[\"position\"][\"row\"]), column=int(obj[\"position\"][\"column\"]))\n",
    "    )\n",
    "world.place_agent_at(\n",
    "    Position(\n",
    "        row=int(situation[\"agent_position\"][\"row\"]), \n",
    "        column=int(situation[\"agent_position\"][\"column\"])\n",
    "))\n",
    "_ = world.render_simple()\n",
    "print(example[\"target_commands\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_array = world.render_simple(array_only=True)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(world_array)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "fig.savefig(\n",
    "    f\"../../../data-files/example.png\", \n",
    "    dpi=500, bbox_inches='tight'\n",
    ")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for the new length split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../../codes/Reason-SCAN/data-files/ReaSCAN-Causal-ICLR-Official-new-length/data-train.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = ReaSCAN_data_json[\"examples\"][\"train\"]\n",
    "max_target_commands_len = -1\n",
    "for example in all_data:\n",
    "    seq_len = len(example['target_commands'].split(\",\"))\n",
    "    if seq_len > max_target_commands_len:\n",
    "        max_target_commands_len = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(max_target_commands_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dist_data = []\n",
    "out_dist_data = []\n",
    "for example in all_data:\n",
    "    seq_len = len(example['target_commands'].split(\",\"))\n",
    "    if seq_len >= 11: # 11 or 12 or 13\n",
    "        out_dist_data += [example]\n",
    "    else:\n",
    "        in_dist_data += [example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 85000 # we want to lower this number a bit from the fullset to make training time reasonable.\n",
    "eval_len = int(85000*0.05) # let us take 5% for dev and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(in_dist_data)\n",
    "train_set = in_dist_data[:train_len]\n",
    "dev_set = in_dist_data[-2*eval_len:-eval_len]\n",
    "test_set = in_dist_data[-eval_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReaSCAN_data_json[\"examples\"] = {\n",
    "    \"train\":train_set,\n",
    "    \"test\":test_set,\n",
    "    \"dev\":dev_set,\n",
    "    \"new_action_length\":out_dist_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to the disk.\n",
    "with open(\"../../../data-files/ReaSCAN-novel-length/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(ReaSCAN_data_json, fd, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPRECATED: Prepare for the new direction split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../../codes/Reason-SCAN/data-files/ReaSCAN-Causal-ICLR-Official/data-train.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = ReaSCAN_data_json[\"examples\"][\"train\"]\n",
    "in_dist_data = []\n",
    "out_dist_data = []\n",
    "for example in all_data:\n",
    "    if \"walk\" not in example[\"command\"]:\n",
    "        assert False\n",
    "    if example[\"adverb_in_command\"] != \"\":\n",
    "        assert False\n",
    "    agent_r = int(example['situation']['agent_position'][\"row\"])\n",
    "    agent_c = int(example['situation']['agent_position'][\"column\"])\n",
    "    target_r = int(example['situation']['target_object']['position'][\"row\"])\n",
    "    target_c = int(example['situation']['target_object']['position'][\"column\"])\n",
    "    r_diff = target_r-agent_r\n",
    "    c_diff = target_c-agent_c\n",
    "    if r_diff > 0 and c_diff < 0:\n",
    "        out_dist_data += [example]\n",
    "    else:\n",
    "        in_dist_data += [example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 85000 # we want to lower this number a bit from the fullset to make training time reasonable.\n",
    "eval_len = int(len(in_dist_data)*0.05) # let us take 5% for dev and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(in_dist_data)\n",
    "train_set = in_dist_data[:train_len]\n",
    "dev_set = in_dist_data[-2*eval_len:-eval_len]\n",
    "test_set = in_dist_data[-eval_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(out_dist_data)\n",
    "ReaSCAN_data_json[\"examples\"] = {\n",
    "    \"train\":train_set,\n",
    "    \"test\":test_set,\n",
    "    \"dev\":dev_set,\n",
    "    \"new_direction\":out_dist_data[:8000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to the disk.\n",
    "with open(\"../../../data-files/ReaSCAN-novel-direction/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(ReaSCAN_data_json, fd, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for the new attribute split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../../codes/Reason-SCAN/data-files/ReaSCAN-Causal-ICLR-Official/data-train.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = ReaSCAN_data_json[\"examples\"][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_color = []\n",
    "new_size = []\n",
    "in_dist_data = []\n",
    "for example in all_data:\n",
    "    if \"yellow,square\" in example['command']:\n",
    "        new_color += [example]\n",
    "    elif \"small,cylinder\" in example['command'] or \\\n",
    "        \"small,red,cylinder\" in example['command'] or \\\n",
    "        \"small,blue,cylinder\" in example['command'] or \\\n",
    "        \"small,yellow,cylinder\" in example['command'] or \\\n",
    "        \"small,green,cylinder\" in example['command']:\n",
    "        new_size += [example]\n",
    "    else:\n",
    "        in_dist_data += [example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 85000 # we want to lower this number a bit from the fullset to make training time reasonable.\n",
    "eval_len = int(train_len*0.05) # let us take 5% for dev and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(in_dist_data)\n",
    "train_set = in_dist_data[:train_len]\n",
    "dev_set = in_dist_data[-2*eval_len:-eval_len]\n",
    "test_set = in_dist_data[-eval_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(new_color)\n",
    "random.shuffle(new_size)\n",
    "ReaSCAN_data_json[\"examples\"] = {\n",
    "    \"train\":train_set,\n",
    "    \"test\":test_set,\n",
    "    \"dev\":dev_set,\n",
    "    \"new_color\":new_color[:8000],\n",
    "    \"new_size\":new_size[:8000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to the disk.\n",
    "with open(\"../../../data-files/ReaSCAN-novel-attribute/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(ReaSCAN_data_json, fd, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us filter out very long sequence length\n",
    "# they are not the focus on this project and\n",
    "# burden training time a lot : )\n",
    "path_to_data = \"../../../data-files/ReaSCAN-novel-attribute/data-compositional-splits.txt\"\n",
    "ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_color = []\n",
    "new_size = []\n",
    "train_data = []\n",
    "dev_data = []\n",
    "test_data = []\n",
    "for k, v in ReaSCAN_data_json[\"examples\"].items():\n",
    "    for example in v:\n",
    "        action_len = len(example[\"target_commands\"].split(\",\"))\n",
    "        if action_len > 35:\n",
    "            continue\n",
    "        if k == \"train\":\n",
    "            train_data += [example]\n",
    "        elif k == \"dev\":\n",
    "            dev_data += [example]\n",
    "        elif k == \"test\":\n",
    "            test_data += [example]\n",
    "        elif k == \"new_color\":\n",
    "            new_color += [example]\n",
    "        elif k == \"new_size\":\n",
    "            new_size += [example]\n",
    "        else:\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReaSCAN_data_json[\"examples\"] = {\n",
    "    \"train\":train_data,\n",
    "    \"test\":test_data,\n",
    "    \"dev\":dev_data,\n",
    "    \"new_color\":new_color[:8000],\n",
    "    \"new_size\":new_size[:8000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to the disk.\n",
    "with open(\"../../../data-files/ReaSCAN-novel-attribute/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(ReaSCAN_data_json, fd, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate vocab files for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../../data-files/\"\n",
    "datasets = [\n",
    "    \"ReaSCAN-novel-attribute\",\n",
    "    \"ReaSCAN-novel-length\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 10:38 Formulating the dataset from the passed in json file...\n",
      "2021-09-28 10:38 Generating vocabularies...\n",
      "2021-09-28 10:38 Populating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procecssing dataset=ReaSCAN-novel-attribute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 10:40 Done generating vocabularies.\n",
      "2021-09-28 10:41 Formulating the dataset from the passed in json file...\n",
      "2021-09-28 10:41 Generating vocabularies...\n",
      "2021-09-28 10:41 Populating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procecssing dataset=ReaSCAN-novel-length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 10:42 Done generating vocabularies.\n"
     ]
    }
   ],
   "source": [
    "basic_stats = {}\n",
    "for ds in datasets:\n",
    "    path_to_data = os.path.join(dataset_path, ds, \"data-compositional-splits.txt\")\n",
    "    ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))\n",
    "    print(f\"procecssing dataset={ds}\")\n",
    "    train_dataset = ReaSCANDataset(\n",
    "        data_json=ReaSCAN_data_json, \n",
    "        save_directory=os.path.join(dataset_path, ds), \n",
    "        k=0, \n",
    "        split=\"train\", \n",
    "        generate_vocabulary=True\n",
    "    )\n",
    "    train_dataset.save_vocabularies(\n",
    "        input_vocabulary_file=\"input_vocabulary.txt\", \n",
    "        target_vocabulary_file=\"target_vocabulary.txt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will simply verify all testing vocab are seen during training.\n",
    "# for novel attributes, we want to make sure different composits are\n",
    "# seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify vocab are consistent.\n",
    "dataset_path = \"../../../data-files/\"\n",
    "datasets = [\n",
    "    \"gSCAN-novel-direction\",\n",
    "    \"ReaSCAN-novel-attribute\",\n",
    "    \"ReaSCAN-novel-action-length\"\n",
    "]\n",
    "\n",
    "for ds in datasets:\n",
    "    print(f\"verifying dataset={ds}\")\n",
    "    path_to_input_vocab = os.path.join(dataset_path, ds, \"input_vocabulary.txt\")\n",
    "    path_to_target_vocab = os.path.join(dataset_path, ds, \"target_vocabulary.txt\")\n",
    "    input_vocab = json.load(open(path_to_input_vocab, \"r\"))\n",
    "    target_vocab = json.load(open(path_to_target_vocab, \"r\"))\n",
    "    path_to_data = os.path.join(dataset_path, ds, \"data-compositional-splits.txt\")\n",
    "    ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))\n",
    "    for k, v in ReaSCAN_data_json[\"examples\"].items():\n",
    "        for example in v:\n",
    "            for w in example[\"command\"].split(\",\"):\n",
    "                assert w in input_vocab[\"idx_to_word\"]\n",
    "            for w in example[\"target_commands\"].split(\",\"):\n",
    "                assert w in target_vocab[\"idx_to_word\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifying dataset=gSCAN-novel-direction\n",
      "split=train, example count=34343\n",
      "split=test, example count=1201\n",
      "split=dev, example count=357\n",
      "split=situational_1, example count=8282\n",
      "verifying dataset=ReaSCAN-novel-attribute\n",
      "split=train, example count=76102\n",
      "split=test, example count=3816\n",
      "split=dev, example count=3774\n",
      "split=new_color, example count=7195\n",
      "split=new_size, example count=7227\n",
      "verifying dataset=ReaSCAN-novel-length\n",
      "split=train, example count=52662\n",
      "split=test, example count=4250\n",
      "split=dev, example count=4250\n",
      "split=new_action_length, example count=1338\n"
     ]
    }
   ],
   "source": [
    "# verify vocab are consistent.\n",
    "dataset_path = \"../../../data-files/\"\n",
    "datasets = [\n",
    "    \"gSCAN-novel-direction\",\n",
    "    \"ReaSCAN-novel-attribute\",\n",
    "    \"ReaSCAN-novel-length\"\n",
    "]\n",
    "\n",
    "for ds in datasets:\n",
    "    print(f\"verifying dataset={ds}\")\n",
    "    path_to_data = os.path.join(dataset_path, ds, \"data-compositional-splits.txt\")\n",
    "    ReaSCAN_data_json = json.load(open(path_to_data, \"r\"))\n",
    "    for k, v in ReaSCAN_data_json[\"examples\"].items():\n",
    "        print(f\"split={k}, example count={len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
