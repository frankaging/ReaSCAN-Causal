{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '../multimodal_seq2seq_gSCAN/'))\n",
    "import random\n",
    "import copy \n",
    "\n",
    "from seq2seq.gSCAN_dataset import GroundedScanDataset\n",
    "from seq2seq.model import Model\n",
    "from seq2seq.train import train\n",
    "from seq2seq.predict import predict_and_save\n",
    "from tqdm import tqdm, trange\n",
    "from GroundedScan.dataset import GroundedScan\n",
    "\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from seq2seq.gSCAN_dataset import Vocabulary\n",
    "from seq2seq.helpers import sequence_accuracy\n",
    "from experiments_utils import *\n",
    "\n",
    "FORMAT = \"%(asctime)-15s %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.DEBUG,\n",
    "                    datefmt=\"%Y-%m-%d %H:%M\")\n",
    "logger = logging.getLogger(__name__)\n",
    "def isnotebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "use_cuda = True if torch.cuda.is_available() and not isnotebook() else False\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "\n",
    "if use_cuda:\n",
    "    logger.info(\"Using CUDA.\")\n",
    "    logger.info(\"Cuda version: {}\".format(torch.version.cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_syntactic_dependency(flags):\n",
    "    for argument, value in flags.items():\n",
    "        logger.info(\"{}: {}\".format(argument, value))\n",
    "\n",
    "    # 1. preparing datasets\n",
    "    logger.info(\"Loading datasets.\")\n",
    "    compositional_splits_data_path = os.path.join(flags[\"data_directory\"], \"dataset.txt\")\n",
    "    compositional_splits_preprocessor = DummyGroundedScanDataset(compositional_splits_data_path, \n",
    "                                            flags[\"data_directory\"], \n",
    "                                            input_vocabulary_file=flags[\"input_vocab_path\"], \n",
    "                                            target_vocabulary_file=flags[\"target_vocab_path\"],\n",
    "                                            generate_vocabulary=False,\n",
    "                                            k=flags[\"k\"])\n",
    "    compositional_splits_dataset = \\\n",
    "        GroundedScan.load_dataset_from_file(\n",
    "            compositional_splits_data_path, \n",
    "            save_directory=flags[\"output_directory\"], \n",
    "            k=flags[\"k\"])\n",
    "\n",
    "    logger.info(\"Loading models.\")\n",
    "    # 2. load up models\n",
    "    raw_example = None\n",
    "    for _, example in enumerate(compositional_splits_dataset.get_examples_with_image(flags[\"split\"], True)):\n",
    "        raw_example = example\n",
    "        break\n",
    "    single_example = compositional_splits_preprocessor.process(raw_example)\n",
    "    model = Model(input_vocabulary_size=compositional_splits_preprocessor.input_vocabulary_size,\n",
    "                  target_vocabulary_size=compositional_splits_preprocessor.target_vocabulary_size,\n",
    "                  num_cnn_channels=compositional_splits_preprocessor.image_channels,\n",
    "                  input_padding_idx=compositional_splits_preprocessor.input_vocabulary.pad_idx,\n",
    "                  target_pad_idx=compositional_splits_preprocessor.target_vocabulary.pad_idx,\n",
    "                  target_eos_idx=compositional_splits_preprocessor.target_vocabulary.eos_idx,\n",
    "                  **input_flags)\n",
    "    model = model.cuda() if use_cuda else model\n",
    "    _ = model.load_model(flags[\"resume_from_file\"])\n",
    "    \n",
    "    # TODO: let us enable multi-gpu settings here to save up times\n",
    "    \n",
    "    logger.info(\"Starting evaluations.\")\n",
    "    input_levDs = []\n",
    "    pred_levDs = []\n",
    "    accuracies = []\n",
    "    corrupt_accuracies = []\n",
    "    example_count = 0\n",
    "    limit = flags[\"max_testing_examples\"]\n",
    "    split = flags[\"split\"]\n",
    "    dataloader = [example for example in compositional_splits_dataset.get_examples_with_image(split, True)]\n",
    "\n",
    "    random.shuffle(dataloader) # shuffle this to get a unbiased estimate of accuracies\n",
    "\n",
    "    dataloader = dataloader[:limit] if limit else dataloader\n",
    "    \n",
    "    for _, example in enumerate(tqdm(dataloader, desc=\"Iteration\")):\n",
    "\n",
    "        # non-corrupt\n",
    "        single_example = compositional_splits_preprocessor.process(example)\n",
    "        output = predict_single(single_example, model=model, \n",
    "                                max_decoding_steps=30, \n",
    "                                pad_idx=compositional_splits_preprocessor.target_vocabulary.pad_idx, \n",
    "                                sos_idx=compositional_splits_preprocessor.target_vocabulary.sos_idx,\n",
    "                                eos_idx=compositional_splits_preprocessor.target_vocabulary.eos_idx, \n",
    "                                device=device)\n",
    "        pred_command = compositional_splits_preprocessor.array_to_sentence(output[3], vocabulary=\"target\")\n",
    "        accuracy = sequence_accuracy(output[3], output[4][0].tolist()[1:-1])\n",
    "        accuracies += [accuracy]\n",
    "\n",
    "        # corrupt\n",
    "        corrupt_example = make_corrupt_example(example, flags[\"corrupt_methods\"])\n",
    "        corrupt_single_example = compositional_splits_preprocessor.process(corrupt_example)\n",
    "        corrupt_output = predict_single(corrupt_single_example, model=model, \n",
    "                                        max_decoding_steps=30, \n",
    "                                        pad_idx=compositional_splits_preprocessor.target_vocabulary.pad_idx, \n",
    "                                        sos_idx=compositional_splits_preprocessor.target_vocabulary.sos_idx,\n",
    "                                        eos_idx=compositional_splits_preprocessor.target_vocabulary.eos_idx, \n",
    "                                        device=device)\n",
    "        corrupt_pred_command = compositional_splits_preprocessor.array_to_sentence(corrupt_output[3], vocabulary=\"target\")\n",
    "        corrupt_accuracy = sequence_accuracy(corrupt_output[3], corrupt_output[4][0].tolist()[1:-1])\n",
    "        corrupt_accuracies += [corrupt_accuracy]\n",
    "\n",
    "        input_levD = levenshteinDistance(example['input_command'], corrupt_example['input_command'])\n",
    "        pred_levD = levenshteinDistance(pred_command, corrupt_pred_command)\n",
    "        input_levDs.append(input_levD)\n",
    "        pred_levDs.append(pred_levD)\n",
    "        example_count += 1\n",
    "\n",
    "    exact_match = 0\n",
    "    for acc in accuracies:\n",
    "        if acc == 100:\n",
    "            exact_match += 1\n",
    "    exact_match = exact_match * 1.0 / len(accuracies)\n",
    "    \n",
    "    corrupt_exact_match = 0\n",
    "    for acc in corrupt_accuracies:\n",
    "        if acc == 100:\n",
    "            corrupt_exact_match += 1\n",
    "    corrupt_exact_match = corrupt_exact_match * 1.0 / len(corrupt_accuracies)\n",
    "            \n",
    "    logger.info(\"Eval Split={}, Original Exact Match %={}, Corrupt Exact Match %={}\".format(split, exact_match, corrupt_exact_match))\n",
    "\n",
    "    return {\"input_levDs\" : input_levDs, \n",
    "            \"pred_levDs\" : pred_levDs, \n",
    "            \"accuracies\" : accuracies, \n",
    "            \"corrupt_accuracies\" : corrupt_accuracies}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_flags = vars(get_gSCAN_parser().parse_args())\n",
    "    \n",
    "    saved_to_dict = evaluate_syntactic_dependency(flags=input_flags)\n",
    "    split = input_flags[\"split\"]\n",
    "    corrupt_methods = input_flags[\"corrupt_methods\"]\n",
    "    if input_flags[\"save_eval_result_dict\"]:\n",
    "        torch.save(saved_to_dict, \n",
    "                   os.path.join(\n",
    "                       input_flags[\"output_directory\"],\n",
    "                       f\"eval_result_split_{split}_corrupt_{corrupt_methods}_dict.bin\")\n",
    "                  )\n",
    "    else:\n",
    "        logger.info(\"Skip saving results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
